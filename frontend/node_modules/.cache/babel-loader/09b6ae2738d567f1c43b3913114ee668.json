{"ast":null,"code":"export const criacao = \"A figura a seguir mostra um diagrama esquemático do processo de construção – do web scraping ao pré-processamento de dados – conforme explicado\\\n    nos próximos tópicos.\";\nexport const scraping = \"O dataset foi inicialmente criado para apoiar pesquisas sobre tarefas de PNL e ML na literatura brasileira e portuguesa. Assim, como fontes de dados\\\n    primárias, consideramos três bibliotecas digitais bem conhecidas para obras de domínio público principalmente do Brasil e Portugal:\\\n    Domínio Público, Projecto Adamastor,  e Biblioteca Digital de Literatura de Países Lusófonos (BLPL). Domínio Público é uma biblioteca digital mantida pelo Ministério da Educação do Brasil e inclui obras devidamente cedidas pelos detentores dos\\\n    direitos autorais. \\\n    O Projecto Adamastor recolhe mais de 1.100 títulos em português de várias fontes de dados, incluindo Domínio Público. BLPL é um grande banco de \\\n    dados de literatura brasileira e portuguesa disponível abertamente, com mais de 80.000 títulos.\\\n    A primeira etapa é implementar um rastreador da web para extrair dados brutos automaticamente de todas as três plataformas, já que nenhuma delas \\\n    fornece uma API. Para isso, usamos BeautifulSoup e Selenium: duas bibliotecas Python populares para web scraping. Extraímos dados tabulares das páginas \\\n    HTML usando web scrapers específicos, pois cada plataforma tem estrutura e formatação exclusivas.  Esse processo aconteceu entre fevereiro e agosto de 2021.\\\n    Para o Projecto Adamastor, esta fase foi simplesmente realizada de forma simples e direta, por extraindo todos os registros de seu banco de dados.\\\n    O Domínio Público oferece quatro tipos de mídia pesquisáveis ​​(texto, imagem, som, vídeo), e muitas categorias e idiomas para consulta, que exigiam \\\n    filtragem para extrair apenas textos referentes à literatura em português. O BLPL possui uma forma baseada na seqüência do alfabeto, exigindo \\\n    então a seleção de cada letra para avançar na busca. Além disso, como um dos objetivos do dataset é extrair texto de obras literárias, criamos \\\n    um sinalizador binário baseado na disponibilidade dos arquivos para download, um recurso distinto do dataset que também permite a filtragem de \\\n    tais documentos. Como resultado, esta etapa coletou links para download e metadados de mais de 80.000 obras de domínio público.\";\nexport const textoUm = \"oi oi oi\";\nexport const integracao = \" O conjunto de dados preliminar fornece informações diferentes e únicas para cada fonte de dados, como a vida dos autores (Projecto Adamastor), os géneros \\\n  literários (BLPL) e o número total de acessos (Domínio Público). A tabela 1 informa os metadados coletados de cada plataforma. \\\n  Com essas informações heterogêneas, usamos uma fonte de dados adicional para integrar e centralizar o conteúdo do conjunto de dados preliminar. Escolhemos \\\n  Goodreads - o maior site do mundo para leitores e recomendações de livros, devido ao seu grande volume de dados disponíveis e sua API de fácil acesso.  \\\n  Por meio de uma API de interface Python, buscamos todos os trabalhos coletados, buscando \\\n  correspondências na plataforma Goodreads. Em particular, os registros do BLPL foram pré-filtrados para manter apenas a obra literária e com o arquivo \\\n  disponível para download, reduzindo-o de 79.208 para 6.480 registros .\\\n  Este estágio de integração de dados também requer uma abordagem de vinculação de registros, já que cada fonte de dados possui um sistema de identificação \\\n  de livros diferente. Esse problema geralmente é resolvido por meio de métodos de correspondência probabilística ou difusa, que aplicam funções de \\\n  similaridade de strings. Aqui, usamos a biblioteca Python fuzzywuzzy para mapear os registros de livros que se referem à mesma entidade em todos fontes. \\\n  A biblioteca usa a distância de Levenshtein para calcular as diferenças entre duas strings. Com uma proporção parcial definida em 75%, o processo de \\\n  correspondência de string difusa gera um resultado incompleto. No total, conseguimos mapear cerca de 25 % (ou seja, 2.388 registros de um total de 9.585) \\\n  dos registros iniciais coletados. A tabela 1 apresenta estatísticas sobre todo o processo antes Registros com Downloads e depois da integração.\";\nexport const extracao = \"Os IDs das obras no conjunto de dados integrado Goodreads possibilitaram coletar informações do autor e da revisão online. Por meio da mesma API Goodreads,\\\n     coletamos metadados de 966 autores, incluindo nome, cidade natal e contagem de fãs. Também criamos outro web scraper para extrair o texto das primeiras \\\n     30 análises online de cada trabalho. Ao final, foram coletadas 4.240 resenhas de 518 trabalhos distintos, além de 1.430 leitores distintos.\";\nexport const preprocessamento = \"As duas últimas etapas do processo são limpeza de dados e engenharia de recursos. Embora Goodreads continue sendo uma fonte valiosa de informações sobre\\\n   livros, também é uma fonte de dados do mundo real. Como resultado, dados ausentes e barulhentos são inevitáveis, o que requer procedimentos de limpeza\\\n   para lidar com registros corrompidos ou imprecisos. \\\n   Primeiro, lidamos com os dados perdidos descartando variáveis ​​irrelevantes e imputando valores perdidos categóricos como uma categoria desconhecido. \\\n   Em seguida, limpamos e tokenizamos o campo de descrição do trabalho usando a biblioteca Python re. Também analisamos e convertemos alguns campos \\\n   estruturados em listas, incluindo  textit {autores},  textit {estantes populares} e  textit {livros semelhantes}. Finalmente, todos os dados \\\n   de identificação dos leitores de  textit {GoodreadsReviews} foram protegidos usando um método de anonimato baseado em hash, convertendo-o em \\\n   um código numérico.\\\n   Na etapa de Engenharia de Recursos, criamos novos recursos a partir dos dados existentes coletados. No Goodreads, um livro pode ser armazenado nas\\\n   prateleiras dos usuários e definido usando tags fixas e personalizadas. Extraímos tags significativas das estantes populares das obras relacionadas \\\n   ao gênero literário e informações de popularidade (por exemplo, número de usuários que rotularam a obra como favorito, para leitura e leitura atual. \\\n   Também criamos alguns recursos quantitativos relacionados ao número total de autores, estantes populares e livros semelhantes; e agrupou as \\\n   categorias de formato de trabalho em três:  textit {físico},  textit {digital} e  textit {desconhecido}.\";\nexport const conteudo = \"O mecanismo de armazenamento usado para dataset é um sistema de gerenciamento de banco de dados relacional (RDBMS). A figura do esquema mostra seu \\\n   12 tabelas divididas em três versões de dataset disponíveis: Preliminary, Goodreads e Full. Essa divisão visa atender a diferentes aplicações dos usuários \\\n   finais, facilitando o acesso aos dados que realmente lhes interessam. A Figura do esquema também inclui a cardinalidade das tabelas principais, enquanto a \\\n   Tabela X apresenta informações quantitativas sobre as versões.\\\n   Preliminar: A versão Preliminar inclui quatro tabelas referentes às três bibliotecas digitais e o conjunto de dados preliminar. Conforme mencionado \\\n   anteriormente, cada biblioteca digital apresenta um conjunto de características diferentes. Portanto, disponibilizamos cada um separadamente, com o \\\n   PreliminaryDataset} atuando como uma tabela compilada concatenando todos os registros por seu ID, a fonte da biblioteca digital e o link para download.\\\n   Goodreads: A versão do Goodreads inclui sete tabelas referentes a obras, autores, resenhas online e gêneros literários. Para cada um desses elementos do \\\n   contexto de publicação do livro, existem vários metadados disponíveis na API Goodreads e os recursos adicionais gerados na etapa de Engenharia de Recursos. \\\n   Além disso, para representar as relações entre tais elementos, criamos três tabelas de junção: WorksAuthors, WorksReviews e WorksGenres. \\\n   Full: Esta versão combina as duas primeiras versões e a tabela DigitalLibraryGoodreads, que armazena o resultado da integração de dados \\\n   , resultando em 12 tabelas.\";\nexport const analise = \"Desenvolvemos uma breve análise exploratória de dados para investigar o conjunto de dados do dataset com curadoria e aprimoramento e com foco de resumir\\\n    suas principais características. Todos os detalhes de análise serão apresentados na seção correspondente com a visualização dos dados de diferentes formas.\";\nexport const formatoUso = \"O dataset está publicamente disponível em um repositório Zenodo de acesso aberto, mas também pode ser baixado na seção de download.\\\n   Como mencionado acima, todos os dados coletados e enriquecidos estão disponíveis em três partes separadas versões (Preliminar, Goodreads e Completa).\\\n   Portanto, geramos um arquivo de despejo para cada versão que contém a estrutura e o conteúdo do banco de dados, que pode ser importado para qualquer \\\n   servidor MySQL. Como o conjunto de dados está estruturado em formato tabular, também disponibilizamos as três versões no formato .csv, o que facilita\\\n   o processamento em notebooks, por exemplo.\";\nexport const desafios = \"O dataset não está livre de desafios, que podem ser enfrentados em versões futuras.\\\n    \\\n    Nesta seção, discutimos brevemente os principais desafios e limitações, que estão principalmente relacionados à heterogeneidade das fontes de dados \\\n    utilizadas no processo de coleta.\\\n    \\\n    Integração de dados:\\\n    Ao juntar diferentes conjuntos de dados com base em entidades que podem (ou não) compartilhar um identificador comum, um método de vinculação de registros\\\n     é frequentemente necessário, o que também foi feito aqui.\\\n    Aplicamos uma abordagem de correspondência difusa, em que pares de registros com probabilidades acima de um certo limite foram considerados a mesma entidade.\\\n    No entanto, embora a lógica difusa seja normalmente um método melhor do que a correspondência determinística, ela está sujeita a erros de ortografia e de\\\n    formatação. Soluções possíveis: não há muito a fazer em relação a trabalhos que não estão realmente presentes no Goodreads, exceto mantê-los apenas no\\\n     conjunto preliminar; e outra opção é pesquisar manualmente no site por aqueles mapeados incorretamente.\\\n    \\\n    Qualidade de dados:\\\n    Além de ser o maior site do mundo para leitores e recomendações de livros, o Goodreads também é uma plataforma de mídia social. Portanto, como qualquer\\\n     outra fonte de dados do mundo real, muito de seu conteúdo disponível é imputado por seus usuários, estando então sujeito à imprecisão e à falta de \\\n     informações.\\\n    Solução possível: para considerar uma fonte de dados adicional para tentar imputar o conteúdo incompleto.\\\n    \\\n    Gêneros distintos:\\\n    Outro problema decorrente da integração de dados é a distinção de gênero entre as fontes de dados, onde apenas duas possuem gêneros literários: \\\n    Projecto Adamastor e BLPL. No primeiro, o campo word_category compreende 54 gêneros; enquanto no último,\\\n    o campo work_genre contém 354 gêneros. Ao comparar os dois conjuntos, eles compartilham apenas quatro gêneros literários Histórias, Biografia, Cartas e\\\n    Memórias. \\\n    Solução possível: para considerar abordagens de correspondência difusa para encontrar gêneros semelhantes.\";","map":{"version":3,"sources":["/Users/clarissescofield/Desktop/POC/lectio/src/features/dataset/Docstexts.js"],"names":["criacao","scraping","textoUm","integracao","extracao","preprocessamento","conteudo","analise","formatoUso","desafios"],"mappings":"AAAA,OAAO,MAAMA,OAAO,GAClB;AACF,0BAFO;AAIP,OAAO,MAAMC,QAAQ,GACnB;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oIAfO;AAiBP,OAAO,MAAMC,OAAO,GAAG,UAAhB;AAEP,OAAO,MAAMC,UAAU,GACrB;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kJAbO;AAeP,OAAO,MAAMC,QAAQ,GACnB;AACF;AACA,iJAHO;AAKP,OAAO,MAAMC,gBAAgB,GAC3B;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4GAbO;AAeP,OAAO,MAAMC,QAAQ,GAClB;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAZO;AAcP,OAAO,MAAMC,OAAO,GACjB;AACH,gKAFO;AAIP,OAAO,MAAMC,UAAU,GACpB;AACH;AACA;AACA;AACA,8CALO;AAOP,OAAO,MAAMC,QAAQ,GACjB;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+GAzBO","sourcesContent":["export const criacao =\n  \"A figura a seguir mostra um diagrama esquemático do processo de construção – do web scraping ao pré-processamento de dados – conforme explicado\\\n    nos próximos tópicos.\";\n\nexport const scraping =\n  \"O dataset foi inicialmente criado para apoiar pesquisas sobre tarefas de PNL e ML na literatura brasileira e portuguesa. Assim, como fontes de dados\\\n    primárias, consideramos três bibliotecas digitais bem conhecidas para obras de domínio público principalmente do Brasil e Portugal:\\\n    Domínio Público, Projecto Adamastor,  e Biblioteca Digital de Literatura de Países Lusófonos (BLPL). Domínio Público é uma biblioteca digital mantida pelo Ministério da Educação do Brasil e inclui obras devidamente cedidas pelos detentores dos\\\n    direitos autorais. \\\n    O Projecto Adamastor recolhe mais de 1.100 títulos em português de várias fontes de dados, incluindo Domínio Público. BLPL é um grande banco de \\\n    dados de literatura brasileira e portuguesa disponível abertamente, com mais de 80.000 títulos.\\\n    A primeira etapa é implementar um rastreador da web para extrair dados brutos automaticamente de todas as três plataformas, já que nenhuma delas \\\n    fornece uma API. Para isso, usamos BeautifulSoup e Selenium: duas bibliotecas Python populares para web scraping. Extraímos dados tabulares das páginas \\\n    HTML usando web scrapers específicos, pois cada plataforma tem estrutura e formatação exclusivas.  Esse processo aconteceu entre fevereiro e agosto de 2021.\\\n    Para o Projecto Adamastor, esta fase foi simplesmente realizada de forma simples e direta, por extraindo todos os registros de seu banco de dados.\\\n    O Domínio Público oferece quatro tipos de mídia pesquisáveis ​​(texto, imagem, som, vídeo), e muitas categorias e idiomas para consulta, que exigiam \\\n    filtragem para extrair apenas textos referentes à literatura em português. O BLPL possui uma forma baseada na seqüência do alfabeto, exigindo \\\n    então a seleção de cada letra para avançar na busca. Além disso, como um dos objetivos do dataset é extrair texto de obras literárias, criamos \\\n    um sinalizador binário baseado na disponibilidade dos arquivos para download, um recurso distinto do dataset que também permite a filtragem de \\\n    tais documentos. Como resultado, esta etapa coletou links para download e metadados de mais de 80.000 obras de domínio público.\";\n\nexport const textoUm = \"oi oi oi\";\n\nexport const integracao =\n  \" O conjunto de dados preliminar fornece informações diferentes e únicas para cada fonte de dados, como a vida dos autores (Projecto Adamastor), os géneros \\\n  literários (BLPL) e o número total de acessos (Domínio Público). A tabela 1 informa os metadados coletados de cada plataforma. \\\n  Com essas informações heterogêneas, usamos uma fonte de dados adicional para integrar e centralizar o conteúdo do conjunto de dados preliminar. Escolhemos \\\n  Goodreads - o maior site do mundo para leitores e recomendações de livros, devido ao seu grande volume de dados disponíveis e sua API de fácil acesso.  \\\n  Por meio de uma API de interface Python, buscamos todos os trabalhos coletados, buscando \\\n  correspondências na plataforma Goodreads. Em particular, os registros do BLPL foram pré-filtrados para manter apenas a obra literária e com o arquivo \\\n  disponível para download, reduzindo-o de 79.208 para 6.480 registros .\\\n  Este estágio de integração de dados também requer uma abordagem de vinculação de registros, já que cada fonte de dados possui um sistema de identificação \\\n  de livros diferente. Esse problema geralmente é resolvido por meio de métodos de correspondência probabilística ou difusa, que aplicam funções de \\\n  similaridade de strings. Aqui, usamos a biblioteca Python fuzzywuzzy para mapear os registros de livros que se referem à mesma entidade em todos fontes. \\\n  A biblioteca usa a distância de Levenshtein para calcular as diferenças entre duas strings. Com uma proporção parcial definida em 75%, o processo de \\\n  correspondência de string difusa gera um resultado incompleto. No total, conseguimos mapear cerca de 25 % (ou seja, 2.388 registros de um total de 9.585) \\\n  dos registros iniciais coletados. A tabela 1 apresenta estatísticas sobre todo o processo antes Registros com Downloads e depois da integração.\";\n\nexport const extracao =\n  \"Os IDs das obras no conjunto de dados integrado Goodreads possibilitaram coletar informações do autor e da revisão online. Por meio da mesma API Goodreads,\\\n     coletamos metadados de 966 autores, incluindo nome, cidade natal e contagem de fãs. Também criamos outro web scraper para extrair o texto das primeiras \\\n     30 análises online de cada trabalho. Ao final, foram coletadas 4.240 resenhas de 518 trabalhos distintos, além de 1.430 leitores distintos.\";\n\nexport const preprocessamento =\n  \"As duas últimas etapas do processo são limpeza de dados e engenharia de recursos. Embora Goodreads continue sendo uma fonte valiosa de informações sobre\\\n   livros, também é uma fonte de dados do mundo real. Como resultado, dados ausentes e barulhentos são inevitáveis, o que requer procedimentos de limpeza\\\n   para lidar com registros corrompidos ou imprecisos. \\\n   Primeiro, lidamos com os dados perdidos descartando variáveis ​​irrelevantes e imputando valores perdidos categóricos como uma categoria desconhecido. \\\n   Em seguida, limpamos e tokenizamos o campo de descrição do trabalho usando a biblioteca Python re. Também analisamos e convertemos alguns campos \\\n   estruturados em listas, incluindo  textit {autores},  textit {estantes populares} e  textit {livros semelhantes}. Finalmente, todos os dados \\\n   de identificação dos leitores de  textit {GoodreadsReviews} foram protegidos usando um método de anonimato baseado em hash, convertendo-o em \\\n   um código numérico.\\\n   Na etapa de Engenharia de Recursos, criamos novos recursos a partir dos dados existentes coletados. No Goodreads, um livro pode ser armazenado nas\\\n   prateleiras dos usuários e definido usando tags fixas e personalizadas. Extraímos tags significativas das estantes populares das obras relacionadas \\\n   ao gênero literário e informações de popularidade (por exemplo, número de usuários que rotularam a obra como favorito, para leitura e leitura atual. \\\n   Também criamos alguns recursos quantitativos relacionados ao número total de autores, estantes populares e livros semelhantes; e agrupou as \\\n   categorias de formato de trabalho em três:  textit {físico},  textit {digital} e  textit {desconhecido}.\";\n\nexport const conteudo =\n   \"O mecanismo de armazenamento usado para dataset é um sistema de gerenciamento de banco de dados relacional (RDBMS). A figura do esquema mostra seu \\\n   12 tabelas divididas em três versões de dataset disponíveis: Preliminary, Goodreads e Full. Essa divisão visa atender a diferentes aplicações dos usuários \\\n   finais, facilitando o acesso aos dados que realmente lhes interessam. A Figura do esquema também inclui a cardinalidade das tabelas principais, enquanto a \\\n   Tabela X apresenta informações quantitativas sobre as versões.\\\n   Preliminar: A versão Preliminar inclui quatro tabelas referentes às três bibliotecas digitais e o conjunto de dados preliminar. Conforme mencionado \\\n   anteriormente, cada biblioteca digital apresenta um conjunto de características diferentes. Portanto, disponibilizamos cada um separadamente, com o \\\n   PreliminaryDataset} atuando como uma tabela compilada concatenando todos os registros por seu ID, a fonte da biblioteca digital e o link para download.\\\n   Goodreads: A versão do Goodreads inclui sete tabelas referentes a obras, autores, resenhas online e gêneros literários. Para cada um desses elementos do \\\n   contexto de publicação do livro, existem vários metadados disponíveis na API Goodreads e os recursos adicionais gerados na etapa de Engenharia de Recursos. \\\n   Além disso, para representar as relações entre tais elementos, criamos três tabelas de junção: WorksAuthors, WorksReviews e WorksGenres. \\\n   Full: Esta versão combina as duas primeiras versões e a tabela DigitalLibraryGoodreads, que armazena o resultado da integração de dados \\\n   , resultando em 12 tabelas.\"\n\nexport const analise = \n   \"Desenvolvemos uma breve análise exploratória de dados para investigar o conjunto de dados do dataset com curadoria e aprimoramento e com foco de resumir\\\n    suas principais características. Todos os detalhes de análise serão apresentados na seção correspondente com a visualização dos dados de diferentes formas.\"\n\nexport const formatoUso =\n   \"O dataset está publicamente disponível em um repositório Zenodo de acesso aberto, mas também pode ser baixado na seção de download.\\\n   Como mencionado acima, todos os dados coletados e enriquecidos estão disponíveis em três partes separadas versões (Preliminar, Goodreads e Completa).\\\n   Portanto, geramos um arquivo de despejo para cada versão que contém a estrutura e o conteúdo do banco de dados, que pode ser importado para qualquer \\\n   servidor MySQL. Como o conjunto de dados está estruturado em formato tabular, também disponibilizamos as três versões no formato .csv, o que facilita\\\n   o processamento em notebooks, por exemplo.\"\n\nexport const desafios = \n    \"O dataset não está livre de desafios, que podem ser enfrentados em versões futuras.\\\n    \\\n    Nesta seção, discutimos brevemente os principais desafios e limitações, que estão principalmente relacionados à heterogeneidade das fontes de dados \\\n    utilizadas no processo de coleta.\\\n    \\\n    Integração de dados:\\\n    Ao juntar diferentes conjuntos de dados com base em entidades que podem (ou não) compartilhar um identificador comum, um método de vinculação de registros\\\n     é frequentemente necessário, o que também foi feito aqui.\\\n    Aplicamos uma abordagem de correspondência difusa, em que pares de registros com probabilidades acima de um certo limite foram considerados a mesma entidade.\\\n    No entanto, embora a lógica difusa seja normalmente um método melhor do que a correspondência determinística, ela está sujeita a erros de ortografia e de\\\n    formatação. Soluções possíveis: não há muito a fazer em relação a trabalhos que não estão realmente presentes no Goodreads, exceto mantê-los apenas no\\\n     conjunto preliminar; e outra opção é pesquisar manualmente no site por aqueles mapeados incorretamente.\\\n    \\\n    Qualidade de dados:\\\n    Além de ser o maior site do mundo para leitores e recomendações de livros, o Goodreads também é uma plataforma de mídia social. Portanto, como qualquer\\\n     outra fonte de dados do mundo real, muito de seu conteúdo disponível é imputado por seus usuários, estando então sujeito à imprecisão e à falta de \\\n     informações.\\\n    Solução possível: para considerar uma fonte de dados adicional para tentar imputar o conteúdo incompleto.\\\n    \\\n    Gêneros distintos:\\\n    Outro problema decorrente da integração de dados é a distinção de gênero entre as fontes de dados, onde apenas duas possuem gêneros literários: \\\n    Projecto Adamastor e BLPL. No primeiro, o campo word_category compreende 54 gêneros; enquanto no último,\\\n    o campo work_genre contém 354 gêneros. Ao comparar os dois conjuntos, eles compartilham apenas quatro gêneros literários Histórias, Biografia, Cartas e\\\n    Memórias. \\\n    Solução possível: para considerar abordagens de correspondência difusa para encontrar gêneros semelhantes.\""]},"metadata":{},"sourceType":"module"}